# -*- coding: utf-8 -*-
"""golf_task.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10A1LNeM0LOFYy8P4YqU52fOPIVMEPyoz
"""

!pip install ultralytics

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="IF01Txx4dAplHHtecf0N")
project = rf.workspace("demo-usfit").project("golf_task-c1bjy")
version = project.version(2)
dataset = version.download("yolov11")

from ultralytics import YOLO
model=YOLO("yolo11n.pt")
model.train(data="/content/golf_task-2/data.yaml",epochs=30,batch=4)

from google.colab import files

uploaded = files.upload()

from ultralytics import YOLO
import cv2
from google.colab.patches import cv2_imshow

# Load YOLO model
model = YOLO("/content/runs/detect/train/weights/best.pt")

# Open video file
video_path = "/content/Great Putting Drill to Show Different Lines Based on Speed shorts golf (online-video-cutter.com).mp4"
cap = cv2.VideoCapture(video_path)

# Get video properties
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = cap.get(cv2.CAP_PROP_FPS)

# Prepare video writer
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter("output_golf.mp4", fourcc, fps, (width, height))

# Process each frame
frame_count = 0
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Run detection
    results = model(frame)[0]
    golf_ball = None
    golf_hole = None

    for r in results.boxes.data.tolist():
        x1, y1, x2, y2, conf, cls = r
        label = model.names[int(cls)]

        if label == 'Golf_ball':
           golf_ball = (int((x1 + x2) / 2), int((y1 + y2) / 2))
        # Draw bounding box
           cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 255, 0), 2)
        # Put label text
           cv2.putText(frame, "Golf_ball", (int(x1), int(y1) - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)

        elif label == 'Golf_hole':
             golf_hole = (int((x1 + x2) / 2), int((y1 + y2) / 2))
        # Draw bounding box
             cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
        # Put label text
             cv2.putText(frame, "Golf_hole", (int(x1), int(y1) - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)


    # Check if the ball is near the hole
    if golf_ball and golf_hole:
        distance = ((golf_ball[0] - golf_hole[0]) ** 2 + (golf_ball[1] - golf_hole[1]) ** 2) ** 0.5
        print(f"golf_ball values are {golf_ball} & golf_hole valueas are {golf_hole}. next is golf_ball[0]: {golf_ball[0]} & golf_hole[0]: {golf_hole[0]} and distance is {distance}")
        if distance < 60:
            text = "The putt is achieved"
            font_scale = 2.2
            thickness = 5
            font = cv2.FONT_HERSHEY_SIMPLEX
            color = (0, 0, 255)
            text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)
            text_x = int((frame.shape[1] - text_size[0]) / 2)
            text_y = 80
            cv2.putText(frame, text, (text_x, text_y), font, font_scale, color, thickness)

    # Save annotated frame to video
    out.write(frame)

    # Show only first few frames in Colab to avoid crashing
    if frame_count < 5:
        cv2_imshow(frame)
    frame_count += 1

# Release resources
cap.release()
out.release()
print("Video processing complete. Output saved as output_golf.mp4")